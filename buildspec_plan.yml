# version: 0.2

# env:
#   variables:
#     TF_PLUGIN_CACHE_DIR: /root/.terraform.d/plugin-cache
#     # Set ARTIFACT_BUCKET in the CodeBuild project / pipeline env
#     # ARTIFACT_BUCKET: my-tf-artifacts-bucket

# phases:
#   install:
#     commands:
#       - yum update -y && yum install -y unzip
#       - curl -sSLO https://releases.hashicorp.com/terraform/1.5.7/terraform_1.5.7_linux_amd64.zip
#       - unzip -o terraform_1.5.7_linux_amd64.zip && mv terraform /usr/local/bin/
#       - mkdir -p "${TF_PLUGIN_CACHE_DIR}"
#       - terraform version
#       - pip install -r requirements.txt

#   pre_build:
#     commands:
#       - echo "Detecting changed jobs"
#       # - docker login --username "$DOCKER_HUB_USERNAME" --password "$DOCKER_HUB_PASSWORD"
#       - git fetch origin "+refs/heads/*:refs/remotes/origin/*" --depth=50 || true
#       - |
#         if git rev-parse --verify HEAD^ >/dev/null 2>&1; then
#           BASE_COMMIT=$(git rev-parse HEAD^)
#           CHANGED_JOBS=$(git diff --name-only "$BASE_COMMIT" HEAD | grep -E '^jobs/[^/]+/' | cut -d'/' -f2 | sort -u)
#         else
#           CHANGED_JOBS=$(ls -1 jobs || true)
#         fi
#       - echo "CHANGED_JOBS=$CHANGED_JOBS"

#       - echo "Build wheels for changed jobs"
#       - |
#         for job in $CHANGED_JOBS; do
#           [ -d "jobs/$job" ] || continue
#           pushd "jobs/$job" >/dev/null
#           rm -rf ./dist ./utils-0.1-py3-none-any.whl
#           docker build -t glue-job-builder .
#           CID=$(docker create glue-job-builder)
#           docker cp "$CID":/out/utils-0.1-py3-none-any.whl ./utils-0.1-py3-none-any.whl
#           docker rm "$CID"
#           popd >/dev/null
#         done

#   build:
#     commands:
#       - |
#         set -e
#         for job in $CHANGED_JOBS; do
#           [ -d "jobs/$job" ] || continue
#           echo "=== Planning $job ==="
#           terraform -chdir="jobs/$job" fmt -recursive
#           terraform -chdir="jobs/$job" init -input=false -backend-config=terraform.tfbackend
#           terraform -chdir="jobs/$job" validate -no-color
#           # plan; allow detailed exit codes without failing the build
#           if terraform -chdir="jobs/$job" plan -no-color -input=false -var-file=terraform.tfvars -out=tfplan -detailed-exitcode; then
#             :
#           else
#             EXIT=$?; [ "$EXIT" -eq 2 ] || exit "$EXIT"
#           fi
#           terraform -chdir="jobs/$job" show -no-color tfplan > "tfplan.txt" || true
#           terraform -chdir="jobs/$job" show -json tfplan > "tfplan.json" || true
#         done

#   post_build:
#     commands:
#       - |
#         set -e
#         ARTIFACT_BUCKET=${ARTIFACT_BUCKET:?Set ARTIFACT_BUCKET env var}
#         COMMIT=${CODEBUILD_RESOLVED_SOURCE_VERSION:-manual-$(date +%s)}
#         echo "Uploading plan artifacts to s3://${ARTIFACT_BUCKET}/runs/${COMMIT}/jobs/"
#         aws s3 sync jobs/ "s3://${ARTIFACT_BUCKET}/runs/${COMMIT}/jobs/" \
#           --exclude "*" \
#           --include "*/tfplan" \
#           --include "*/tfplan.txt" \
#           --include "*/tfplan.json" \
#           --include "*/utils-*.whl" \
#           --include "*/requirements.txt"

#         # Write 'latest.txt' without process substitution
#         printf %s "$COMMIT" | aws s3 cp - "s3://${ARTIFACT_BUCKET}/runs/latest.txt" \
#           --content-type text/plain --cache-control no-store
#         echo "Uploaded artifacts for commit ${COMMIT}"

# artifacts:
#   files:
#     - jobs/**/tfplan
#     - jobs/**/tfplan.txt
#     - jobs/**/tfplan.json
#     - jobs/**/utils-0.1-py3-none-any.whl
#     - jobs/**/requirements.txt
#   discard-paths: no

# cache:
#   paths:
#     - /root/.terraform.d/plugin-cache/**





version: 0.2

env:
  variables:
    TF_PLUGIN_CACHE_DIR: "/root/.terraform.d/plugin-cache"
    # Set this in CodeBuild environment variables
    # ARTIFACT_BUCKET: my-tf-artifacts-bucket
    # Optionally for Docker Hub (if needed)
    # DOCKER_HUB_USERNAME: ""
    # DOCKER_HUB_PASSWORD: ""

phases:
  install:
    commands:
      - yum update -y && yum install -y unzip
      - curl -sSLO https://releases.hashicorp.com/terraform/1.5.7/terraform_1.5.7_linux_amd64.zip
      - unzip -o terraform_1.5.7_linux_amd64.zip && mv terraform /usr/local/bin/
      - mkdir -p "${TF_PLUGIN_CACHE_DIR}"
      - terraform version
      # Root requirements are optional; keep if you need Python tooling at root
      - |
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi

  pre_build:
    commands:
      - echo "Fetching recent commit history"
      - git fetch origin "+refs/heads/*:refs/remotes/origin/*" --depth=50 || true

      # Detect changed directories across jobs/ and sp_jobs/
      - |
        if git rev-parse --verify HEAD^ >/dev/null 2>&1; then
          BASE=$(git rev-parse HEAD^)
          CHANGED_DIRS=$(git diff --name-only "$BASE" HEAD \
            | grep -E "^(jobs|sp_jobs)/[^/]+/" \
            | cut -d/ -f1-2 \
            | sort -u || true)
        else
          # First build: consider all first-level dirs under jobs and sp_jobs
          CHANGED_DIRS="$(find jobs sp_jobs -mindepth 1 -maxdepth 1 -type d 2>/dev/null | sort)"
        fi
      - echo "CHANGED_DIRS=${CHANGED_DIRS:-<none>}"

      # Identify Glue jobs as those under jobs/<name> that have a Dockerfile
      - |
        GLUE_JOBS=""
        for dir in $CHANGED_DIRS; do
          case "$dir" in
            jobs/*)
              if [ -f "$dir/Dockerfile" ]; then
                job_name="$(basename "$dir")"
                GLUE_JOBS="${GLUE_JOBS} ${job_name}"
              fi
              ;;
          esac
        done
        GLUE_JOBS="$(echo "$GLUE_JOBS" | xargs -n1 | sort -u | xargs || true)"
      - echo "GLUE_JOBS=${GLUE_JOBS:-<none>}"

      # Optional docker login if you pull bases from private registry
      # - docker login --username "$DOCKER_HUB_USERNAME" --password "$DOCKER_HUB_PASSWORD"

      # Build wheels for changed Glue jobs (only if Dockerfile exists)
      - echo "Building wheels for changed Glue jobs (if any)"
      - |
        for job in $GLUE_JOBS; do
          [ -d "jobs/$job" ] || continue
          pushd "jobs/$job" >/dev/null
          rm -rf ./dist ./utils-0.1-py3-none-any.whl
          echo "==> docker build glue-job-builder: jobs/$job"
          docker build -t glue-job-builder .
          CID=$(docker create glue-job-builder)
          docker cp "$CID":/out/utils-0.1-py3-none-any.whl ./utils-0.1-py3-none-any.whl || true
          docker rm "$CID" >/dev/null 2>&1 || true
          popd >/dev/null
        done

  build:
    commands:
      # Terraform for every changed directory (both Redshift and Glue)
      - |
        set -e
        for dir in $CHANGED_DIRS; do
          [ -d "$dir" ] || continue
          echo "=== Terraform: $dir ==="
          terraform -chdir="$dir" fmt -recursive || true
          terraform -chdir="$dir" init -input=false -backend-config=terraform.tfbackend
          # Validate available in both job types; ignore failure if not applicable
          terraform -chdir="$dir" validate -no-color || true
          # Plan with detailed exit codes; only fail on non-0/2
          if terraform -chdir="$dir" plan -no-color -input=false -var-file=terraform.tfvars -out=tfplan -detailed-exitcode; then
            :
          else
            EXIT=$?; [ "$EXIT" -eq 2 ] || exit "$EXIT"
          fi
          terraform -chdir="$dir" show -no-color tfplan > "$dir/tfplan.txt" || true
          terraform -chdir="$dir" show -json tfplan > "$dir/tfplan.json" || true
        done

  post_build:
    commands:
      - |
        set -e
        ARTIFACT_BUCKET=${ARTIFACT_BUCKET:?Set ARTIFACT_BUCKET}
        COMMIT=${CODEBUILD_RESOLVED_SOURCE_VERSION:-manual-$(date +%s)}
        echo "Uploading artifacts to s3://${ARTIFACT_BUCKET}/runs/${COMMIT}/"
        # Upload plans and wheels for both jobs/ and sp_jobs/
        aws s3 sync . "s3://${ARTIFACT_BUCKET}/runs/${COMMIT}/" \
          --exclude "*" \
          --include "jobs/*/tfplan" \
          --include "jobs/*/tfplan.txt" \
          --include "jobs/*/tfplan.json" \
          --include "jobs/*/utils-*.whl" \
          --include "jobs/*/requirements.txt" \
          --include "sp_jobs/*/tfplan" \
          --include "sp_jobs/*/tfplan.txt" \
          --include "sp_jobs/*/tfplan.json"

        # Update latest pointer
        printf %s "$COMMIT" | aws s3 cp - "s3://${ARTIFACT_BUCKET}/runs/latest.txt" \
          --content-type text/plain --cache-control no-store
        echo "Uploaded artifacts for commit ${COMMIT}"

artifacts:
  files:
    # Terraform plan artifacts for both redshift and glue job folders
    - jobs/**/tfplan
    - jobs/**/tfplan.txt
    - jobs/**/tfplan.json
    - sp_jobs/**/tfplan
    - sp_jobs/**/tfplan.txt
    - sp_jobs/**/tfplan.json
    # Glue wheel & per-job requirements (only present for glue jobs)
    - jobs/**/utils-0.1-py3-none-any.whl
    - jobs/**/requirements.txt
  discard-paths: no

cache:
  paths:
    - /root/.terraform.d/plugin-cache/**
